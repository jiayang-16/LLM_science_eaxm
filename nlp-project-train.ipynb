{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":54662,"databundleVersionId":6169864,"sourceType":"competition"},{"sourceId":6170048,"sourceType":"datasetVersion","datasetId":3540267},{"sourceId":6175087,"sourceType":"datasetVersion","datasetId":3540289},{"sourceId":6315195,"sourceType":"datasetVersion","datasetId":3626780},{"sourceId":6572938,"sourceType":"datasetVersion","datasetId":3600418},{"sourceId":7641324,"sourceType":"datasetVersion","datasetId":4453526},{"sourceId":7667849,"sourceType":"datasetVersion","datasetId":4471930}],"dockerImageVersionId":30648,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-21T12:58:03.055786Z","iopub.execute_input":"2024-02-21T12:58:03.056243Z","iopub.status.idle":"2024-02-21T12:58:03.439985Z","shell.execute_reply.started":"2024-02-21T12:58:03.056207Z","shell.execute_reply":"2024-02-21T12:58:03.439037Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/kaggle-llm-science-exam/sample_submission.csv\n/kaggle/input/kaggle-llm-science-exam/train.csv\n/kaggle/input/kaggle-llm-science-exam/test.csv\n/kaggle/input/additional-train-data-for-llm-science-exam/6000_train_examples.csv\n/kaggle/input/additional-train-data-for-llm-science-exam/extra_train_set.csv\n/kaggle/input/test-with-infer/test_with_infer.csv\n/kaggle/input/test-with-infer-15k/test_with_infer_15k.csv\n/kaggle/input/deberta-v3-large-hf-weights/spm.model\n/kaggle/input/deberta-v3-large-hf-weights/config.json\n/kaggle/input/deberta-v3-large-hf-weights/tokenizer_config.json\n/kaggle/input/deberta-v3-large-hf-weights/pytorch_model.bin\n/kaggle/input/15k-high-quality-examples/5900_examples.csv\n/kaggle/input/15k-high-quality-examples/15k_gpt3.5-turbo.csv\n/kaggle/input/llm-whls/einops-0.6.1-py3-none-any.whl\n/kaggle/input/llm-whls/tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n/kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl\n/kaggle/input/llm-whls/transformers-4.34.0.dev0-py3-none-any.whl\n/kaggle/input/llm-whls/datasets-2.14.3-py3-none-any.whl\n/kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n/kaggle/input/llm-whls/transformers-4.33.3-py3-none-any.whl\n/kaggle/input/llm-whls/bitsandbytes-0.41.1-py3-none-any.whl\n/kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Process","metadata":{}},{"cell_type":"code","source":"!pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n\nfrom typing import Optional, Union\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom datasets import Dataset\nfrom dataclasses import dataclass\nfrom transformers import AutoTokenizer\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, AutoModel\nfrom peft import LoraConfig, get_peft_model, TaskType\n\ndeberta_v3_large= '/kaggle/input/deberta-v3-large-hf-weights'","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:58:03.442135Z","iopub.execute_input":"2024-02-21T12:58:03.442521Z","iopub.status.idle":"2024-02-21T12:58:23.584609Z","shell.execute_reply.started":"2024-02-21T12:58:03.442495Z","shell.execute_reply":"2024-02-21T12:58:23.583781Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\nInstalling collected packages: peft\nSuccessfully installed peft-0.4.0\n","output_type":"stream"},{"name":"stderr","text":"2024-02-21 12:58:14.948784: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-21 12:58:14.948902: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-21 12:58:15.082656: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/15k-high-quality-examples/5900_examples.csv\").dropna().reset_index(drop=True)\ntest = pd.concat([test.iloc[:400],pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/train.csv\").drop(\"id\", axis=1)])\ntest_infer = pd.read_csv(\"/kaggle/input/test-with-infer/test_with_infer.csv\").iloc[:,:-2]\nprint(test.shape)\nprint(test_infer.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:58:23.585820Z","iopub.execute_input":"2024-02-21T12:58:23.586570Z","iopub.status.idle":"2024-02-21T12:58:23.753139Z","shell.execute_reply.started":"2024-02-21T12:58:23.586533Z","shell.execute_reply":"2024-02-21T12:58:23.752040Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(600, 7)\n(600, 7)\n","output_type":"stream"}]},{"cell_type":"code","source":"test_infer.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:58:23.755140Z","iopub.execute_input":"2024-02-21T12:58:23.755476Z","iopub.status.idle":"2024-02-21T12:58:23.772575Z","shell.execute_reply.started":"2024-02-21T12:58:23.755449Z","shell.execute_reply":"2024-02-21T12:58:23.771590Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  Too Much TV is a British television programme,...   \n1  The 1919–20 Navy Midshipmen men's basketball t...   \n2  The original series, , is collected in 20 volu...   \n3  Several qualitative observations can be made o...   \n4  The A4113 road is a single-carriageway road th...   \n\n                                                   B  \\\n0  Exploring the history and evolution of British...   \n1                                               1905   \n2                                        Ten volumes   \n3  The angular spacing of features in the diffrac...   \n4                            Powys and Herefordshire   \n\n                                                   D  \\\n0  Showcasing a wide range of television programm...   \n1                                               1945   \n2                                      Three volumes   \n3  The angular spacing of features in the diffrac...   \n4                             Knighton and Bromfield   \n\n                                                   C  \\\n0  Investigating the effects of excessive televis...   \n1                                               1957   \n2                                      Seven volumes   \n3  The angular spacing of features in the diffrac...   \n4                               Powys and Shropshire   \n\n                                                   E  \\\n0  Analyzing the impact of excessive television c...   \n1                                               1920   \n2                                         One volume   \n3  The angular spacing of features in the diffrac...   \n4                        Herefordshire and Bromfield   \n\n                                                   A answer  \n0  Examining the different genres and formats of ...      D  \n1                                               1893      A  \n2                                       Five volumes      B  \n3  The angular spacing of features in the diffrac...      C  \n4                            Shropshire and Knighton      B  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>B</th>\n      <th>D</th>\n      <th>C</th>\n      <th>E</th>\n      <th>A</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Too Much TV is a British television programme,...</td>\n      <td>Exploring the history and evolution of British...</td>\n      <td>Showcasing a wide range of television programm...</td>\n      <td>Investigating the effects of excessive televis...</td>\n      <td>Analyzing the impact of excessive television c...</td>\n      <td>Examining the different genres and formats of ...</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The 1919–20 Navy Midshipmen men's basketball t...</td>\n      <td>1905</td>\n      <td>1945</td>\n      <td>1957</td>\n      <td>1920</td>\n      <td>1893</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The original series, , is collected in 20 volu...</td>\n      <td>Ten volumes</td>\n      <td>Three volumes</td>\n      <td>Seven volumes</td>\n      <td>One volume</td>\n      <td>Five volumes</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Several qualitative observations can be made o...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The A4113 road is a single-carriageway road th...</td>\n      <td>Powys and Herefordshire</td>\n      <td>Knighton and Bromfield</td>\n      <td>Powys and Shropshire</td>\n      <td>Herefordshire and Bromfield</td>\n      <td>Shropshire and Knighton</td>\n      <td>B</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# validation = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv')\n# validation.dropna(inplace=True)\n# validation.reset_index(inplace=True,drop=True)\nvalidation = pd.read_csv(\"/kaggle/input/test-with-infer-15k/test_with_infer_15k.csv\").iloc[:100,:-2]\nprint(validation.shape)\ndf_train = pd.read_csv(\"/kaggle/input/15k-high-quality-examples/15k_gpt3.5-turbo.csv\")\ndf_train.dropna(inplace=True)\ndf_train.reset_index(inplace=True,drop=True)\ndf_train = pd.concate([pd.read_csv(\"/kaggle/input/test-with-infer-15k/test_with_infer_15k.csv\").iloc[-100:,:-2], df_train])\nprint(df_train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:58:23.773671Z","iopub.execute_input":"2024-02-21T12:58:23.773956Z","iopub.status.idle":"2024-02-21T12:58:24.077996Z","shell.execute_reply.started":"2024-02-21T12:58:23.773931Z","shell.execute_reply":"2024-02-21T12:58:24.076979Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(100, 7)\n(14993, 7)\n","output_type":"stream"}]},{"cell_type":"code","source":"option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\nindex_to_option = {v: k for k,v in option_to_index.items()}\ntokenizer = AutoTokenizer.from_pretrained(deberta_v3_large)\n\ndef preprocess(example):\n    first_sentence = [example['prompt']] * 5\n    second_sentences = [example[option] for option in 'ABCDE']\n    tokenized_example = tokenizer(first_sentence, second_sentences, truncation=False)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    \n    return tokenized_example\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:58:24.079553Z","iopub.execute_input":"2024-02-21T12:58:24.080118Z","iopub.status.idle":"2024-02-21T12:58:25.309752Z","shell.execute_reply.started":"2024-02-21T12:58:24.080078Z","shell.execute_reply":"2024-02-21T12:58:25.308942Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:515: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = Dataset.from_pandas(df_train)\nprint(dataset)\ntokenized_dataset = dataset.map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\nprint(tokenized_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:58:25.310844Z","iopub.execute_input":"2024-02-21T12:58:25.311140Z","iopub.status.idle":"2024-02-21T12:58:39.920541Z","shell.execute_reply.started":"2024-02-21T12:58:25.311114Z","shell.execute_reply":"2024-02-21T12:58:39.919603Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'],\n    num_rows: 14993\n})\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/14993 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64bf27321cd64e97b0788c8c47e3f2b9"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n    num_rows: 14993\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_test = Dataset.from_pandas(test).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\nprint(tokenized_test)\ntokenized_test_infer = Dataset.from_pandas(test_infer).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\nprint(tokenized_test_infer)\ntokenized_validation = Dataset.from_pandas(validation).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\nprint(tokenized_validation)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:58:39.921696Z","iopub.execute_input":"2024-02-21T12:58:39.921990Z","iopub.status.idle":"2024-02-21T12:58:45.210024Z","shell.execute_reply.started":"2024-02-21T12:58:39.921964Z","shell.execute_reply":"2024-02-21T12:58:45.209242Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/600 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2959a43449fd4bcd8ce5d70ffda67cc8"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n    num_rows: 600\n})\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/600 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08ee1f492e8846b69e42f762bc471436"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n    num_rows: 600\n})\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"851015b9c67f403ba638bdc5f54b0acb"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n    num_rows: 100\n})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"def map_at_3(predictions, labels):\n    map_sum = 0\n    pred = np.argsort(-1*np.array(predictions),axis=1)[:,:3]\n    for x,y in zip(pred,labels):\n        z = [1/i if y==j else 0 for i,j in zip([1,2,3],x)]\n        map_sum += np.sum(z)\n    return map_sum / len(predictions)\n\n\ndef compute_metrics(p):\n    predictions = p.predictions.tolist()\n    labels = p.label_ids.tolist()\n    return {\"map@3\": map_at_3(predictions, labels)}","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:58:45.211122Z","iopub.execute_input":"2024-02-21T12:58:45.211411Z","iopub.status.idle":"2024-02-21T12:58:45.217938Z","shell.execute_reply.started":"2024-02-21T12:58:45.211386Z","shell.execute_reply":"2024-02-21T12:58:45.217034Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForMultipleChoice.from_pretrained(deberta_v3_large)\n# peft_config = LoraConfig(task_type=TaskType.TOKEN_CLS,r=8,\n#                          lora_alpha=16,lora_dropout=0.1,\n# #                          target_modules=[\"query_key_value\"],\n#                          modules_to_save=['classifier','pooler'])\n# model = get_peft_model(model, peft_config)\n\nFREEZE_LAYERS=6\nprint('Freezing embeddings.')\nfor param in model.deberta.embeddings.parameters():\n    param.requires_grad = False\nprint(f'Freezing {FREEZE_LAYERS} layers.')\nfor layer in model.deberta.encoder.layer[:FREEZE_LAYERS]:\n    for param in layer.parameters():\n        param.requires_grad = False\n\ntraining_args = TrainingArguments(\n    learning_rate=1e-5,\n    warmup_ratio=0.1,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=8,\n    num_train_epochs=1,\n    report_to='none',\n    output_dir = f'./checkpoints',\n    overwrite_output_dir=True,\n    fp16=True,\n    gradient_accumulation_steps=8,\n    logging_steps=50,\n    evaluation_strategy='steps',\n    eval_steps=50,\n    save_strategy=\"steps\",\n    save_steps=50,\n    load_best_model_at_end=True,\n    metric_for_best_model='map@3',\n    lr_scheduler_type='cosine',\n#     weight_decay=0.01,\n    save_total_limit=1,\n)\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n    train_dataset=tokenized_dataset,\n    eval_dataset=tokenized_validation,\n    compute_metrics = compute_metrics,\n)\n# model.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:58:45.221596Z","iopub.execute_input":"2024-02-21T12:58:45.222081Z","iopub.status.idle":"2024-02-21T12:58:53.664488Z","shell.execute_reply.started":"2024-02-21T12:58:45.222056Z","shell.execute_reply":"2024-02-21T12:58:53.663466Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at /kaggle/input/deberta-v3-large-hf-weights and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Freezing embeddings.\nFreezing 6 layers.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:58:53.665770Z","iopub.execute_input":"2024-02-21T12:58:53.666117Z","iopub.status.idle":"2024-02-21T13:34:04.652998Z","shell.execute_reply.started":"2024-02-21T12:58:53.666084Z","shell.execute_reply":"2024-02-21T13:34:04.651923Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='468' max='468' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [468/468 35:05, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Map@3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>1.614900</td>\n      <td>1.609219</td>\n      <td>0.446667</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.608700</td>\n      <td>1.608066</td>\n      <td>0.536667</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.497500</td>\n      <td>1.582773</td>\n      <td>0.671667</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.350400</td>\n      <td>1.559941</td>\n      <td>0.670000</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.305300</td>\n      <td>1.559121</td>\n      <td>0.711667</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.294200</td>\n      <td>1.562676</td>\n      <td>0.715000</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.252100</td>\n      <td>1.537060</td>\n      <td>0.728333</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.242400</td>\n      <td>1.542373</td>\n      <td>0.731667</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.250700</td>\n      <td>1.542139</td>\n      <td>0.735000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=468, training_loss=1.3736249157506177, metrics={'train_runtime': 2110.1687, 'train_samples_per_second': 7.105, 'train_steps_per_second': 0.222, 'total_flos': 7161916678487040.0, 'train_loss': 1.3736249157506177, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained(\"model_v1\")","metadata":{"execution":{"iopub.status.busy":"2024-02-21T13:34:04.654350Z","iopub.execute_input":"2024-02-21T13:34:04.654995Z","iopub.status.idle":"2024-02-21T13:34:07.820416Z","shell.execute_reply.started":"2024-02-21T13:34:04.654957Z","shell.execute_reply":"2024-02-21T13:34:07.819560Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"import numpy as np\ndef precision_at_k(r, k):\n    \"\"\"Precision at k\"\"\"\n    assert k <= len(r)\n    assert k != 0\n    return sum(int(x) for x in r[:k]) / k\n\ndef MAP_at_3(predictions, true_items):\n    \"\"\"Score is mean average precision at 3\"\"\"\n    U = len(predictions)\n    map_at_3 = 0.0\n    for u in range(U):\n        user_preds = predictions[u]\n        user_true = true_items.tolist()[u]\n        user_results = [1 if item == user_true else 0 for item in user_preds]\n        for k in range(min(len(user_preds), 3)):\n            map_at_3 += precision_at_k(user_results, k+1) * user_results[k]\n    return map_at_3 / U","metadata":{"execution":{"iopub.status.busy":"2024-02-21T13:34:07.821679Z","iopub.execute_input":"2024-02-21T13:34:07.821976Z","iopub.status.idle":"2024-02-21T13:34:07.830047Z","shell.execute_reply.started":"2024-02-21T13:34:07.821951Z","shell.execute_reply":"2024-02-21T13:34:07.829149Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"prediction = trainer.predict(tokenized_test).predictions\nprediction_letter = np.array(list('ABCDE'))[np.argsort(-prediction, 1)]\nMAP_at_3(prediction_letter, test[\"answer\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-21T13:34:07.831269Z","iopub.execute_input":"2024-02-21T13:34:07.831892Z","iopub.status.idle":"2024-02-21T13:34:33.216038Z","shell.execute_reply.started":"2024-02-21T13:34:07.831859Z","shell.execute_reply":"2024-02-21T13:34:33.215131Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0.7536111111111108"},"metadata":{}}]},{"cell_type":"code","source":"prediction_infer = trainer.predict(tokenized_test_infer).predictions\nprediction_infer_letter = np.array(list('ABCDE'))[np.argsort(-prediction_infer, 1)]\nMAP_at_3(prediction_infer_letter, test_infer[\"answer\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-21T13:34:33.217116Z","iopub.execute_input":"2024-02-21T13:34:33.217444Z","iopub.status.idle":"2024-02-21T13:39:15.021675Z","shell.execute_reply.started":"2024-02-21T13:34:33.217418Z","shell.execute_reply":"2024-02-21T13:39:15.020604Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0.8008333333333328"},"metadata":{}}]},{"cell_type":"code","source":"# trainable parameters\nparams = model.parameters()\nnum_trainable_params = 0\nfor param in model.parameters():\n    if param.requires_grad:\n        num_trainable_params += param.numel()\n\nprint(f\"Number of trainable parameters: {num_trainable_params}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T13:39:15.022849Z","iopub.execute_input":"2024-02-21T13:39:15.023179Z","iopub.status.idle":"2024-02-21T13:39:15.032049Z","shell.execute_reply.started":"2024-02-21T13:39:15.023134Z","shell.execute_reply":"2024-02-21T13:39:15.030972Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Number of trainable parameters: 228308993\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load Model","metadata":{}},{"cell_type":"code","source":"# from peft import PeftModel,PeftConfig\n# # base_model_dir = \"/kaggle/input/deberta-v3-large-hf-weights\"\n# # peft_model_dir = \"/kaggle/working/model_v1\"\n# # test_model = AutoModelForMultipleChoice.from_pretrained(base_model_dir).cuda()\n# # test_model = PeftModel.from_pretrained(test_model, peft_model_dir)\n# model_dir = \"/kaggle/working/model_v1\"\n# test_model = AutoModelForMultipleChoice.from_pretrained(model_dir).cuda()\n# trainer = Trainer(test_model,tokenizer=tokenizer,\n#     data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer))\n# prediction = trainer.predict(tokenized_test).predictions\n# prediction_letter = np.array(list('ABCDE'))[np.argsort(-prediction, 1)]","metadata":{"execution":{"iopub.status.busy":"2024-02-21T13:39:15.033279Z","iopub.execute_input":"2024-02-21T13:39:15.033566Z","iopub.status.idle":"2024-02-21T13:39:15.043573Z","shell.execute_reply.started":"2024-02-21T13:39:15.033542Z","shell.execute_reply":"2024-02-21T13:39:15.042870Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# MAP_at_3(prediction_letter, test[\"answer\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-21T13:39:15.044663Z","iopub.execute_input":"2024-02-21T13:39:15.044990Z","iopub.status.idle":"2024-02-21T13:39:15.054002Z","shell.execute_reply.started":"2024-02-21T13:39:15.044959Z","shell.execute_reply":"2024-02-21T13:39:15.053030Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}